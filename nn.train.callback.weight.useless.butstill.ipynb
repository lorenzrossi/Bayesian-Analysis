{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import keras\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import IsolationForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfk = tf.keras\n",
    "tf.keras.backend.set_floatx(\"float64\")\n",
    "tfd = tfp.distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices(\"GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_global = pd.read_csv('splitted/Total.csv')\n",
    "df_global.drop(columns=[col for col in df_global.columns if col.startswith('time')], inplace=True, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_generation biomass</th>\n",
       "      <th>y_generation nuclear</th>\n",
       "      <th>y_generation other</th>\n",
       "      <th>y_generation other renewable</th>\n",
       "      <th>y_generation solar</th>\n",
       "      <th>y_generation waste</th>\n",
       "      <th>y_price actual</th>\n",
       "      <th>y_generation fossil</th>\n",
       "      <th>y_generation hydro</th>\n",
       "      <th>y_generation wind</th>\n",
       "      <th>...</th>\n",
       "      <th>x_temp_min_Bilbao</th>\n",
       "      <th>x_temp_max_Bilbao</th>\n",
       "      <th>x_pressure_Bilbao</th>\n",
       "      <th>x_humidity_Bilbao</th>\n",
       "      <th>x_wind_speed_Bilbao</th>\n",
       "      <th>x_wind_deg_Bilbao</th>\n",
       "      <th>x_rain_1h_Bilbao</th>\n",
       "      <th>x_rain_3h_Bilbao</th>\n",
       "      <th>x_snow_3h_Bilbao</th>\n",
       "      <th>x_clouds_all_Bilbao</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>447.0</td>\n",
       "      <td>7096.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>65.41</td>\n",
       "      <td>10156.0</td>\n",
       "      <td>3813.0</td>\n",
       "      <td>6378.0</td>\n",
       "      <td>...</td>\n",
       "      <td>269.657312</td>\n",
       "      <td>269.657312</td>\n",
       "      <td>1036.0</td>\n",
       "      <td>97</td>\n",
       "      <td>0.0</td>\n",
       "      <td>226</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>449.0</td>\n",
       "      <td>7096.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>64.92</td>\n",
       "      <td>10437.0</td>\n",
       "      <td>3587.0</td>\n",
       "      <td>5890.0</td>\n",
       "      <td>...</td>\n",
       "      <td>269.763500</td>\n",
       "      <td>269.763500</td>\n",
       "      <td>1035.0</td>\n",
       "      <td>97</td>\n",
       "      <td>0.0</td>\n",
       "      <td>229</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>448.0</td>\n",
       "      <td>7099.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>64.48</td>\n",
       "      <td>9918.0</td>\n",
       "      <td>3508.0</td>\n",
       "      <td>5461.0</td>\n",
       "      <td>...</td>\n",
       "      <td>269.251688</td>\n",
       "      <td>269.251688</td>\n",
       "      <td>1036.0</td>\n",
       "      <td>97</td>\n",
       "      <td>1.0</td>\n",
       "      <td>224</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>438.0</td>\n",
       "      <td>7098.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>59.32</td>\n",
       "      <td>8859.0</td>\n",
       "      <td>3231.0</td>\n",
       "      <td>5238.0</td>\n",
       "      <td>...</td>\n",
       "      <td>269.203344</td>\n",
       "      <td>269.203344</td>\n",
       "      <td>1035.0</td>\n",
       "      <td>97</td>\n",
       "      <td>1.0</td>\n",
       "      <td>225</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>428.0</td>\n",
       "      <td>7097.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>189.0</td>\n",
       "      <td>56.04</td>\n",
       "      <td>8313.0</td>\n",
       "      <td>3499.0</td>\n",
       "      <td>4935.0</td>\n",
       "      <td>...</td>\n",
       "      <td>269.485500</td>\n",
       "      <td>269.485500</td>\n",
       "      <td>1035.0</td>\n",
       "      <td>97</td>\n",
       "      <td>1.0</td>\n",
       "      <td>221</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   y_generation biomass  y_generation nuclear  y_generation other  \\\n",
       "0                 447.0                7096.0                43.0   \n",
       "1                 449.0                7096.0                43.0   \n",
       "2                 448.0                7099.0                43.0   \n",
       "3                 438.0                7098.0                43.0   \n",
       "4                 428.0                7097.0                43.0   \n",
       "\n",
       "   y_generation other renewable  y_generation solar  y_generation waste  \\\n",
       "0                          73.0                49.0               196.0   \n",
       "1                          71.0                50.0               195.0   \n",
       "2                          73.0                50.0               196.0   \n",
       "3                          75.0                50.0               191.0   \n",
       "4                          74.0                42.0               189.0   \n",
       "\n",
       "   y_price actual  y_generation fossil  y_generation hydro  y_generation wind  \\\n",
       "0           65.41              10156.0              3813.0             6378.0   \n",
       "1           64.92              10437.0              3587.0             5890.0   \n",
       "2           64.48               9918.0              3508.0             5461.0   \n",
       "3           59.32               8859.0              3231.0             5238.0   \n",
       "4           56.04               8313.0              3499.0             4935.0   \n",
       "\n",
       "   ...  x_temp_min_Bilbao  x_temp_max_Bilbao  x_pressure_Bilbao  \\\n",
       "0  ...         269.657312         269.657312             1036.0   \n",
       "1  ...         269.763500         269.763500             1035.0   \n",
       "2  ...         269.251688         269.251688             1036.0   \n",
       "3  ...         269.203344         269.203344             1035.0   \n",
       "4  ...         269.485500         269.485500             1035.0   \n",
       "\n",
       "   x_humidity_Bilbao  x_wind_speed_Bilbao  x_wind_deg_Bilbao  \\\n",
       "0                 97                  0.0                226   \n",
       "1                 97                  0.0                229   \n",
       "2                 97                  1.0                224   \n",
       "3                 97                  1.0                225   \n",
       "4                 97                  1.0                221   \n",
       "\n",
       "   x_rain_1h_Bilbao  x_rain_3h_Bilbao  x_snow_3h_Bilbao  x_clouds_all_Bilbao  \n",
       "0               0.0               0.0               0.0                    0  \n",
       "1               0.0               0.0               0.0                    0  \n",
       "2               0.0               0.0               0.0                    0  \n",
       "3               0.0               0.0               0.0                    0  \n",
       "4               0.0               0.0               0.0                    0  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_global.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "nn = MinMaxScaler().fit_transform(df_global)\n",
    "dataset = pd.DataFrame(nn, columns=df_global.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "inputs = [col for col in df_global.columns if col.startswith('x_')]\n",
    "outputs = [col for col in df_global.columns if col.startswith('y_')]\n",
    "\n",
    "x = dataset[inputs]\n",
    "y = dataset[outputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Define helper functions.\n",
    "detector = IsolationForest(n_estimators=1000, random_state=SEED)\n",
    "neg_log_likelihood = lambda x, rv_x: -rv_x.log_prob(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Define some hyperparameters.\n",
    "n_epochs, n_batches, n_samples = 20, 16, dataset.shape[0]\n",
    "buffer_size, batch_size = n_samples, np.floor(n_samples/n_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Define training and test data sizes.\n",
    "n_train, n_test = int(0.70*n_samples), int(0.30*n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Define dataset instance.\n",
    "data = tf.data.Dataset.from_tensor_slices((x.values, y.values))\n",
    "data = data.shuffle(n_samples, reshuffle_each_iteration=True, seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Define train and test data instances.\n",
    "data_train = data.take(n_train).batch(batch_size).repeat(n_epochs)\n",
    "data_test = data.skip(n_train).batch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Define prior for regularization.\n",
    "\n",
    "gauss_prior = tfd.Normal(\n",
    "    loc = tf.zeros( len(outputs), dtype=tf.float64 ),\n",
    "    scale = 1.0, #tf.ones( len(outputs), dtype=tf.float64 ),\n",
    "    name = \"p_normal\",\n",
    "    )\n",
    "\n",
    "prior = tfd.Independent(\n",
    "    gauss_prior,\n",
    "    reinterpreted_batch_ndims = 1,\n",
    "    name = \"prior\",\n",
    "    )\n",
    "\n",
    "regularizer = tfp.layers.KLDivergenceRegularizer(prior, weight=1/n_batches, ) # Kullback–Leibler divergence (also called relative entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def params_size(n) : return sum(range(n+2))-1 # N means + N(N+1)/2 co-variances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Define model instance.\n",
    "model = tfk.Sequential([\n",
    "\n",
    "    tfk.layers.InputLayer(\n",
    "        input_shape=(len(inputs),),\n",
    "        name=\"input\"\n",
    "        ),\n",
    "\n",
    "    # dense for inputs\n",
    "    tfk.layers.Dense(\n",
    "        n_batches,\n",
    "        activation=\"relu\",\n",
    "        name=\"dense_input\"\n",
    "        ),\n",
    "\n",
    "    # # a new dense for input\n",
    "    # tfp.layers.DenseFlipout(\n",
    "    #     10,\n",
    "    #     activation=\"relu\",\n",
    "    #     name=\"dense_1\"\n",
    "    # )\n",
    "\n",
    "    # dense for weights\n",
    "    tfk.layers.Dense(\n",
    "        params_size(len(outputs)), # uncertainty in the parameters weights\n",
    "        activation=None,\n",
    "        name=\"distribution_weights\"\n",
    "        ),\n",
    "\n",
    "    # (declaration of the) posterior probability distribution structure\n",
    "    tfp.layers.MultivariateNormalTriL(\n",
    "        len(outputs),\n",
    "        # activity_regularizer acts as prior for the output layer\n",
    "        activity_regularizer=regularizer, \n",
    "        name=\"output\"),\n",
    "        \n",
    "    ], name=\"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Compile model.\n",
    "model.compile(optimizer=\"adam\", loss=neg_log_likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_weights = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCallback(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        print(f\" ... i'm gonna pickle the model: \")\n",
    "\n",
    "        # model.save_weights(f'epoches/weights.{epoch:02}')\n",
    "        # model.save(f'epoches/model.{epoch:02}')\n",
    "\n",
    "        for l in ['dense_input', 'distribution_weights', 'output']:\n",
    "            layer_weights[epoch, l] = model.get_layer(l).weights\n",
    "\n",
    "        print(f'epoch #{epoch:02} pickled!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "239/240 [============================>.] - ETA: 0s - loss: 1.5260 ... i'm gonna pickle the model: \n",
      "epoch #00 pickled!\n",
      "240/240 [==============================] - 75s 299ms/step - loss: 1.5221 - val_loss: -2.9953\n",
      "Epoch 2/20\n",
      "239/240 [============================>.] - ETA: 0s - loss: -3.3883 ... i'm gonna pickle the model: \n",
      "epoch #01 pickled!\n",
      "240/240 [==============================] - 81s 338ms/step - loss: -3.3884 - val_loss: -3.6650\n",
      "Epoch 3/20\n",
      "239/240 [============================>.] - ETA: 0s - loss: -3.9977 ... i'm gonna pickle the model: \n",
      "epoch #02 pickled!\n",
      "240/240 [==============================] - 71s 298ms/step - loss: -3.9977 - val_loss: -4.1335\n",
      "Epoch 4/20\n",
      "239/240 [============================>.] - ETA: 0s - loss: -4.2503 ... i'm gonna pickle the model: \n",
      "epoch #03 pickled!\n",
      "240/240 [==============================] - 71s 298ms/step - loss: -4.2503 - val_loss: -4.3540\n",
      "Epoch 5/20\n",
      "239/240 [============================>.] - ETA: 0s - loss: -4.4033 ... i'm gonna pickle the model: \n",
      "epoch #04 pickled!\n",
      "240/240 [==============================] - 71s 295ms/step - loss: -4.4033 - val_loss: -4.4758\n",
      "Epoch 6/20\n",
      "239/240 [============================>.] - ETA: 0s - loss: -4.5010 ... i'm gonna pickle the model: \n",
      "epoch #05 pickled!\n",
      "240/240 [==============================] - 72s 299ms/step - loss: -4.5010 - val_loss: -4.5639\n",
      "Epoch 7/20\n",
      "239/240 [============================>.] - ETA: 0s - loss: -4.5688 ... i'm gonna pickle the model: \n",
      "epoch #06 pickled!\n",
      "240/240 [==============================] - 81s 337ms/step - loss: -4.5690 - val_loss: -4.6109\n",
      "Epoch 8/20\n",
      "239/240 [============================>.] - ETA: 0s - loss: -4.6282 ... i'm gonna pickle the model: \n",
      "epoch #07 pickled!\n",
      "240/240 [==============================] - 67s 279ms/step - loss: -4.6281 - val_loss: -4.6755\n",
      "Epoch 9/20\n",
      "239/240 [============================>.] - ETA: 0s - loss: -4.6919 ... i'm gonna pickle the model: \n",
      "epoch #08 pickled!\n",
      "240/240 [==============================] - 65s 273ms/step - loss: -4.6918 - val_loss: -4.7116\n",
      "Epoch 10/20\n",
      "239/240 [============================>.] - ETA: 0s - loss: -4.7479 ... i'm gonna pickle the model: \n",
      "epoch #09 pickled!\n",
      "240/240 [==============================] - 65s 270ms/step - loss: -4.7479 - val_loss: -4.7920\n",
      "Epoch 11/20\n",
      "239/240 [============================>.] - ETA: 0s - loss: -4.7964 ... i'm gonna pickle the model: \n",
      "epoch #10 pickled!\n",
      "240/240 [==============================] - 66s 273ms/step - loss: -4.7964 - val_loss: -4.8207\n",
      "Epoch 12/20\n",
      "240/240 [==============================] - ETA: 0s - loss: -4.8249 ... i'm gonna pickle the model: \n",
      "epoch #11 pickled!\n",
      "240/240 [==============================] - 66s 274ms/step - loss: -4.8249 - val_loss: -4.8470\n",
      "Epoch 13/20\n",
      "239/240 [============================>.] - ETA: 0s - loss: -4.8646 ... i'm gonna pickle the model: \n",
      "epoch #12 pickled!\n",
      "240/240 [==============================] - 69s 290ms/step - loss: -4.8646 - val_loss: -4.8688\n",
      "Epoch 14/20\n",
      "239/240 [============================>.] - ETA: 0s - loss: -4.8906 ... i'm gonna pickle the model: \n",
      "epoch #13 pickled!\n",
      "240/240 [==============================] - 66s 277ms/step - loss: -4.8908 - val_loss: -4.9099\n",
      "Epoch 15/20\n",
      "239/240 [============================>.] - ETA: 0s - loss: -4.9203 ... i'm gonna pickle the model: \n",
      "epoch #14 pickled!\n",
      "240/240 [==============================] - 66s 277ms/step - loss: -4.9200 - val_loss: -4.9378\n",
      "Epoch 16/20\n",
      "239/240 [============================>.] - ETA: 0s - loss: -4.9386 ... i'm gonna pickle the model: \n",
      "epoch #15 pickled!\n",
      "240/240 [==============================] - 74s 308ms/step - loss: -4.9385 - val_loss: -4.9700\n",
      "Epoch 17/20\n",
      "239/240 [============================>.] - ETA: 0s - loss: -4.9667 ... i'm gonna pickle the model: \n",
      "epoch #16 pickled!\n",
      "240/240 [==============================] - 67s 279ms/step - loss: -4.9666 - val_loss: -5.0013\n",
      "Epoch 18/20\n",
      "239/240 [============================>.] - ETA: 0s - loss: -4.9850 ... i'm gonna pickle the model: \n",
      "epoch #17 pickled!\n",
      "240/240 [==============================] - 66s 275ms/step - loss: -4.9852 - val_loss: -5.0124\n",
      "Epoch 19/20\n",
      "239/240 [============================>.] - ETA: 0s - loss: -5.0072 ... i'm gonna pickle the model: \n",
      "epoch #18 pickled!\n",
      "240/240 [==============================] - 69s 286ms/step - loss: -5.0074 - val_loss: -5.0227\n",
      "Epoch 20/20\n",
      "240/240 [==============================] - ETA: 0s - loss: -5.0331 ... i'm gonna pickle the model: \n",
      "epoch #19 pickled!\n",
      "240/240 [==============================] - 74s 308ms/step - loss: -5.0331 - val_loss: -5.0621\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20aca9e5720>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(data_train, epochs=n_epochs, validation_data=data_test, verbose=True, callbacks=[CustomCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(layer_weights, open('layer.weights.foreach.epoch.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
